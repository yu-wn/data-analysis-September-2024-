{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "384180fd-8862-42c0-9dfd-fa5b3273791f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of all_data: (30, 121, 81)\n",
      "Shape of all_data_reshaped: (121, 2430)\n",
      "[[0.46592289 0.48021719 0.47612312 ... 2.16513634 2.3072722  2.15782332]\n",
      " [0.47249496 0.48529342 0.47961375 ... 2.18415809 2.31544828 2.18865514]\n",
      " [0.47001845 0.48797292 0.47988799 ... 2.19842148 2.31258464 2.20771217]\n",
      " ...\n",
      " [0.46917149 0.58395267 0.28469336 ... 1.66282606 1.6382829  1.65504134]\n",
      " [0.50348943 0.59158242 0.29284415 ... 1.67513502 1.65274012 1.65729499]\n",
      " [0.51863384 0.59561086 0.29988927 ... 1.67252219 1.66059899 1.65793395]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# 時系列データを正規化\\nscaler = TimeSeriesScalerMeanVariance()\\nall_data_scaled = scaler.fit_transform(all_data_reshaped)\\nprint(f\"Shape of all_data_scaled: {all_data_scaled.shape}\")\\n\\n# 最後の次元を削除して2次元配列にする\\nall_data_scaled = all_data_scaled.reshape(all_data_scaled.shape[0], -1)  # (121, 2430)\\nprint(f\"Shape of all_data_scaled: {all_data_scaled.shape}\")\\n\\n# TimeSeriesKMeansによるクラスタリング (DTW距離を使用、クラスター数k=3の例)\\nn_clusters = 3\\nmodel = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"dtw\", random_state=0, n_init=10)\\nlabels = model.fit_predict(all_data_scaled)\\n\\n# クラスタラベルを各ファイルに追加して保存\\nfor i, file in enumerate(file_list):\\n    data = pd.read_csv(file)\\n    data[\\'ClusterLabel\\'] = labels[i]  # クラスタラベルを追加\\n    # 新しいファイル名を作成して保存\\n    new_file_name = os.path.join(save_folder_path, os.path.basename(file).replace(\".csv\", \"lavel.csv\"))\\n    data.to_csv(new_file_name, index=False)\\n    print(f\"ファイル: {new_file_name} - クラスタ: {labels[i]} に保存しました。\")\\n\\nprint(\"全てのファイルが正しく保存されました。\")\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# フォルダパスの設定\n",
    "folder_path = \"C:\\\\Users\\\\miyazakipc\\\\Desktop\\\\2024年9月10日　実験\\\\てすりとキネクト（てすり）\\\\データ分析\\\\Kinect\\\\抽出後Kinect\"\n",
    "\n",
    "# 新しい保存先フォルダの設定\n",
    "save_folder_path = \"C:\\\\Users\\\\miyazakipc\\\\Desktop\\\\2024年9月10日　実験\\\\てすりとキネクト（てすり）\\\\データ分析\\\\ラベル付きデータKinect\"\n",
    "os.makedirs(save_folder_path, exist_ok=True)\n",
    "\n",
    "# すべてのCSVファイルのパスを取得\n",
    "file_list = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# 全てのファイルのデータを格納するリスト\n",
    "all_data = []\n",
    "\n",
    "# 各ファイルから座標データを読み込み、リストに追加\n",
    "for file in file_list:\n",
    "    data = pd.read_csv(file)\n",
    "    coordinates = data.iloc[:, 2:83].values\n",
    "    all_data.append(coordinates)\n",
    "\n",
    "# データを結合し、全体のデータセットを作成\n",
    "all_data = np.array(all_data)\n",
    "print(f\"Shape of all_data: {all_data.shape}\")\n",
    "\n",
    "# データを2次元配列に変換 (121, 81×30)\n",
    "all_data_reshaped = all_data.transpose(1, 2, 0).reshape(121, -1)\n",
    "print(f\"Shape of all_data_reshaped: {all_data_reshaped.shape}\")  # (121, 2430)\n",
    "print(all_data_reshaped)\n",
    "\"\"\"\n",
    "# 時系列データを正規化\n",
    "scaler = TimeSeriesScalerMeanVariance()\n",
    "all_data_scaled = scaler.fit_transform(all_data_reshaped)\n",
    "print(f\"Shape of all_data_scaled: {all_data_scaled.shape}\")\n",
    "\n",
    "# 最後の次元を削除して2次元配列にする\n",
    "all_data_scaled = all_data_scaled.reshape(all_data_scaled.shape[0], -1)  # (121, 2430)\n",
    "print(f\"Shape of all_data_scaled: {all_data_scaled.shape}\")\n",
    "\n",
    "# TimeSeriesKMeansによるクラスタリング (DTW距離を使用、クラスター数k=3の例)\n",
    "n_clusters = 3\n",
    "model = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"dtw\", random_state=0, n_init=10)\n",
    "labels = model.fit_predict(all_data_scaled)\n",
    "\n",
    "# クラスタラベルを各ファイルに追加して保存\n",
    "for i, file in enumerate(file_list):\n",
    "    data = pd.read_csv(file)\n",
    "    data['ClusterLabel'] = labels[i]  # クラスタラベルを追加\n",
    "    # 新しいファイル名を作成して保存\n",
    "    new_file_name = os.path.join(save_folder_path, os.path.basename(file).replace(\".csv\", \"lavel.csv\"))\n",
    "    data.to_csv(new_file_name, index=False)\n",
    "    print(f\"ファイル: {new_file_name} - クラスタ: {labels[i]} に保存しました。\")\n",
    "\n",
    "print(\"全てのファイルが正しく保存されました。\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a0070-2b5f-413d-8ea4-a2e630358200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (test)",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
